# Importing necessary libraries
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.neural_network import MLPRegressor
from sklearn.svm import SVC
from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Load the data
student = pd.read_csv("StudentPerformanceFactors.csv")
backup = pd.read_csv("StudentPerformanceFactors.csv")

# Data cleaning
print(student.shape)
print(student.info())
print(student.isnull().sum())
print(student.describe())
print(student.duplicated().sum())

# Data Preprocessing
# Parental_Involvement
student['Parental_Involvement'] = student['Parental_Involvement'].map({'Low': 1, 'Medium': 2, 'High': 3})

# Access_to_Resources
student['Access_to_Resources'] = student['Access_to_Resources'].map({'Low': 1, 'Medium': 2, 'High': 3})

# Extracurricular_Activities
student['Extracurricular_Activities'] = student['Extracurricular_Activities'].map({'Yes': 1, 'No': 0})

# Internet_Access
student['Internet_Access'] = student['Internet_Access'].map({'Yes': 1, 'No': 0})

# Parental_Education_Level
education_map = {'High School': 1, 'College': 2, 'Postgraduate': 3, 'Other': 4}
student['Parental_Education_Level'] = student['Parental_Education_Level'].map(education_map)

# Gender
student['Gender'] = student['Gender'].map({'Male': 1, 'Female': 0})

# Preprocessed Data
processed_data = student.drop(['column8', 'column11', 'column12', 'column13', 'column14', 'column16', 'column18', 'column20'], axis=1)

# Normalization
scaler = MinMaxScaler()
student_n = pd.DataFrame(scaler.fit_transform(processed_data), columns=processed_data.columns)
student_n['Score'] = backup['Exam_Score']

# Train-test split
X = student_n.drop('Score', axis=1)
y = student_n['Score']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)

# Linear Regression
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)
predictions = lin_reg.predict(X_test)
mse = mean_squared_error(y_test, predictions)
print(f'MSE (Linear Regression): {mse}')

# Plotting - Predicted vs Actual
plt.figure(figsize=(8, 5))
sns.scatterplot(x=y_test, y=predictions, color='purple', alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')
plt.title('Predicted vs Actual Scores (Linear Regression)')
plt.xlabel('Actual Scores')
plt.ylabel('Predicted Scores')
plt.show()

# Residual Plot
residuals = y_test - predictions
plt.figure(figsize=(8, 5))
sns.scatterplot(x=y_test, y=residuals, color='red', alpha=0.6)
plt.axhline(0, color='blue', linestyle='dashed')
plt.title('Residual Plot (Linear Regression)')
plt.xlabel('Actual Scores')
plt.ylabel('Residuals')
plt.show()

# Residual Distribution
plt.figure(figsize=(8, 5))
sns.histplot(residuals, bins=30, color='yellow', kde=True)
plt.title('Distribution of Residuals (Linear Regression)')
plt.xlabel('Residuals')
plt.show()
